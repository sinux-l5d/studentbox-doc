{"/":{"title":"üë®‚Äçüíª Studentbox documentation","content":"\n_Studentbox_ is a project that aims to make deployment easy for student üë®‚Äçüéì, and management of hosted projects simple for a teacher üë®‚Äçüè´.\n\n# üåç Context\n\nI've realised this project during my BSc (Hons)[^bsc] at [Dundalk Institute of Technology](https://www.dkit.ie/). The curriculum is about _Cloud Computing_, and so this project has to take advantage of different cloud aspects like including scaling, APIs[^api] and automation etc.\n\nSee the [[about-me|About me]] page this know more about the author.\n\n# ü•ú In a nutshell...\n\n_Studentbox_ wants to archive the following goals:\n\n- Host the students' projects in an isolated environment, without impacting other projects or host system\n- Provide a complete environment for the apps supported\n- Be able to deploy in a single command line...\n  - PHP app using MySQL\n  - Node.js app using MongoDB or MySQL\n- The _CLI_[^cli] client should...\n  - work on Linux, Mac and Windows\n  - be easy to setup\n  - be usable by both student and teacher\n- Make possible live-reloading while developing\n\nWhile having the following constraints:\n\n- Hostable on AWS\n- Self-hostable on an on-premise server\n\nYou can access the [[project/goals|goals]] page to know more about the project's goals and the [[project/road-map|road map]].\n\n[^bsc]:\n    **B**achelor of **Sc**ience (**Hon**our**s**) is the 4th year after secondary school (in Ireland).\n    In France, the equivalent year is the 1st year of Master's degree (the 4th year after _Lyc√©e_).\n\n[^api]: **A**pplication **P**rogramming **I**nterface in IT is an abstraction layer to interact with things we don't want to deal manually with. In this curriculum, we're talking about Web APIs (REST with JSON among others).\n[^cli]:\n    **C**ommand **L**ine **I**nterface, as the opposit of Graphical User Interface (GUI) is a text-based interface.\n    On Windows, it's in CMD/PowerShell. On Linux, it's in your favourite terminal \u0026 shell (bash, zsh...)\n","lastmodified":"2023-02-02T11:28:17.184598373Z","tags":null},"/about-me":{"title":"About me üôã‚Äç‚ôÇÔ∏è","content":"\nMy name is Simon LEONARD. This project has been produced during my 4th year after secondary school/_Lyc√©e_. \n\nWhy am I not writing BSc Hons? And why do I use the French word _Lyc√©e_?\n\nBecause I'm currently a French student, and I'm in a Erasmus+ exchange year in [Dundalk Institute of Technologies](https://www.dkit.ie/) at the time of writing.\\\nAt DkIT I'm following the course _Computing in Cloud Computing_, meanwhile at [Universit√© Savoie Mont-Blanc](https://univ-smb.fr/en) I'm enrolled in the [CMI programme](https://reseau-figure.fr/about-cmi/?lang=en) for IT, which is basically a bundle of BSc + BSc (hons) + MSc + additional courses on 5 years.\n\nSee my [Linkedin](https://linkedin.com/in/simon-l5d) and [Github](https://github.com/sinux-l5d).","lastmodified":"2023-02-02T11:28:17.184598373Z","tags":null},"/project/goals":{"title":"Goals üéØ","content":"\n# Back end\n\nThe back end should be either hosted on AWS or an on-premise server.\n\nAmazon's cloud would be useful if one needs to easily scale as more students use it.\nOn another hand, an on-premise server allow flexibility and complete control other data, privacy and hosting.\n\nThis means that I cannot use AWS's specific service, or at least not without increasing development cost.\n\nFinally, an easy/automated installation would save time.\n\n## Isolate process\n\nWe don't want that students' project impact other's by accident or on purpose.\n\nIf a web app crash, is heavily dealing with I/O, or is stuck in a infinite loop, it should impact as little as possible other projects.\n\n## Data exchange\n\nThe API should be bidirectional, for let's say uploading files and getting live logs of the back end.\n\n## Live reload\n\nLive reload is a convenient feature to allow to see changes as soon as a file is saved. In our case, that would mean upload the changed files and eventually restart the webapp.  \n\n## Users \u0026 permissions\n\nStudent and teachers are both users. Teachers can host his own project, for demonstration purpose let's say. He can invite students to register in his class, and manage the projects associated.\n\n## Git integration üí°\n\nUse Git as part of the API, as a backup/rollback system.\nEach project would have a repository.\n\n# CLI\n\nA CLI client for all users. A student should be able to deploy his project, retrieve logs (possibly in live), get link. A teacher has the same rights as student, plus managing resources, users, projects.\n\nBecause most users use Windows, the CLI needs to be cross platform.\n\n# Front end\n\nSimple webapp that allow the same thing as CLI, in a more graphical manner. No install, drag and drop zip/archive to deploy. \nNote for the ZIP: mind that code might be at root of the archive, not in a top-level directory.\n\nIt should present live logs, just like CLI.\n","lastmodified":"2023-02-02T11:28:17.184598373Z","tags":null},"/project/road-map":{"title":"Road map üó∫Ô∏è","content":"\n\n# Research üîé\n\nThis section treats about everything that needs to be researched before starting to code.\n\n## API \n\nCompare API types, knowing I want to transfer files, and need live-capabilities.\n\n### JSON\n\nSee [[research/api/json|JSON]]\n\n\u003c!-- ![JSON](research/api/json) --\u003e\n\n### REST \n\nSee [[research/api/rest|REST]].\n\n\n### GraphQL\n\nSee [[research/api/graphql|GraphQL]].\n\n### gRPC \u0026 Protobuf\n\nSee [[research/api/protobuf|Protobuf]] and [[research/api/grpc|gRPC]].\n\n## Sand-boxing processes \n\nIt's important that each project is isolated from others and eventually from the host. I need a lightweight system that allow to easily add/remove new project, limiting disk/CPU/memory usage.\n\n### Container approach\n\n#### Docker\n\n#### Podman\n\n#### Kubernetes\n\nSee implementations and API\n\n### Virtual Machines approach\n\n#### Vagrant\n\n#### Self-managed\n\n#### AWS-managed\n\n## Programming language \n\n## Storage\n\nThe app will 2 different types of data: metadata (users, permissions) and the projects themselves (files).\nWhat type of database? Why?\n\n### Users, permissions, projects...\n\n### Projects\n\n## Logic\n\n### Defining permissions\n\n### Recipe for minimal deploy\n\nAll student in mind, write down the simplest way for a user to deploy his php/node.js app.\n\n# Choosing tech stack (by 16th of January)\n\nOnce research is done, make choices.\n\n# Realising","lastmodified":"2023-02-02T11:28:17.184598373Z","tags":null},"/research/api/graphql":{"title":"GraphQL","content":"\n\u003e [!quote] According to the official website\n\u003e\n\u003e GraphQL is a query language for APIs and a runtime for fulfilling those queries with your existing data. GraphQL provides a complete and understandable description of the data in your API, gives clients the power to ask for exactly what they need and nothing more, makes it easier to evolve APIs over time, and enables powerful developer¬†tools.\n\u003e\n\u003e \u003csmall\u003e_GraphQL | A query language for you API_ (no date) _GraphQL_. Available at: https://graphql.org/ (Accessed: January 13, 2023).\u003c/small\u003e\n\nFirst thing we notice is that GraphQL is not just a API specifications but a full runtime[^aimuliple] unlike [[research/api/rest|REST]] which is just a specification.\n\nFor GraphQL, just as for [[research/api/grpc|gRPC]], we need to write specification of the objects we will transfer beforehand. In the GraphQL word, it's called _type definitions_ and types contains _fields_.\n\n\u003e [!example] Example from the official website\n\u003e\n\u003e First describe the objects\n\u003e\n\u003e ```graphql\n\u003e type Project {\n\u003e   name: String\n\u003e   tagline: String\n\u003e   contributors: [User]\n\u003e }\n\u003e ```\n\u003e\n\u003e Then query whatever you want\n\u003e\n\u003e ```graphql\n\u003e {\n\u003e   project(name: \"GraphQL\") {\n\u003e     tagline\n\u003e   }\n\u003e }\n\u003e ```\n\u003e\n\u003e The result will be formatted just like the query\n\u003e\n\u003e ```graphql\n\u003e {\n\u003e   \"project\": {\n\u003e     \"tagline\": \"A query language for APIs\"\n\u003e   }\n\u003e }\n\u003e ```\n\nThose type definition being in separate files, it's easy to document the API automatically with tools like [Graph*i*QL](https://github.com/graphql/graphiql).\n\nOne of the advantages of this query approach is its precision, allowing us to have all the data we need at once, without the need to fetch multiple times like it's the case for REST.\n\n\u003e [!danger] Drawbacks\n\u003e\n\u003e From https://research.aimultiple.com/graphql-vs-rest/\n\u003e\n\u003e 1. GraphQL's single endpoint (`/graphql`) can be a bottleneck, especially because REST allows easy caching on routes.\n\u003e 2. Security is not built in the standard, different alternatives exist.\n\u003e 3. \"While GraphQL offers a caching mechanism, the cache-implementing process is much more complex and time-consuming than REST implementation.\" It's mostly because REST allows caching by using different URLs.\n\u003e 4. GraphQL costs more because queries can be unpredictably large, and a query's cost can be hard to estimate.\n\n## File upload\n\nJust like for REST, we could encode files in base64 to upload them. But that adds overhead for both server and client, increasing the file size by ~33%[^wundergraph].\n\nJust like for REST, we could use a multipart request but:\n\n\u003e [!quote] Quote from Jens Neuse[^wundergraph]\n\u003e\n\u003e Unfortunately, there's no standard to handle Multipart Requests with GraphQL.¬†This means, your solution will not be easily portable across different languages or implementations¬†and your client implementation depends on the exact implementation of the server.\n\nSo one of the other approaches is to have another homemade API in REST that takes care of files only, or using AWS S3. The last option is not viable if we want to keep our system independent from the cloud.\n\nThe article I relied on is made by Jens Neuse at [WunderGraph](https://wundergraph.com), described as \"The¬†simplicity of RPC with the¬†power of GraphQL\" on their website. That could be a solution, but would lock us in a not-so-well-known solution, and we don't control the prices. If I where to use RPC, I would probably go with [[research/api/grpc|gRPC]] which is free, open source and licensed Apache-2.0.\n\n[^aimuliple]: Ataman, A. (2023) _Graphql vs. rest in 2023: Top 4 advantages \u0026 disadvantages_, _AIMultiple_. Available at: https://research.aimultiple.com/graphql-vs-rest/ (Accessed: January 13, 2023).\n[^wundergraph]: Neuse, J. (2021) _GraphQL file uploads - evaluating the 5 most common approaches_, _WunderGraph_. Available at: https://wundergraph.com/blog/graphql_file_uploads_evaluating_the_5_most_common_approaches (Accessed: January 13, 2023).\n","lastmodified":"2023-02-02T11:28:17.184598373Z","tags":null},"/research/api/grpc":{"title":"gRPC","content":"\ngRPC is \"a high performance, open source universal RPC framework\"[^grpcio].\nRPC stands for _Remote Procedure Call_, which is a kind of API that abstracts the complexity of making calls to a remote API by providing to the developer functions that works like if it was local[^wikipedia].\n\n\u003e [!quote] Quote\n\u003e\n\u003e gRPC uses HTTP/2 under the covers, but HTTP is not exposed to the API designer[^googlecloud]\n\ngRPC uses [[research/api/protobuf|Protocol Buffers]] as a serialisation format by default, but can use [[research/api/json|JSON]]. It works by extending the syntax of a `.proto` file.\n\nWe need to define the messages (basic Protobuf structure) that will be exchanged whenever it's an argument or a return value, along with the `services`, that describe the procedures available.\n\n\u003e [!example] Example from official tutorial[^grpcio]\n\u003e\n\u003e First the messages:\n\u003e\n\u003e ```protobuf\n\u003e // The request message containing the user's name.\n\u003e message HelloRequest {\n\u003e   string name = 1;\n\u003e }\n\u003e\n\u003e // The response message containing the greetings\n\u003e message HelloReply {\n\u003e   string message = 1;\n\u003e }\n\u003e ```\n\u003e\n\u003e and then the gRPC syntax to declare a _service, a set of procedures_:\n\u003e\n\u003e ```protobuf\n\u003e // The greeter service definition.\n\u003e service Greeter {\n\u003e   // Sends a greeting\n\u003e   rpc SayHello (HelloRequest) returns (HelloReply) {}\n\u003e }\n\u003e ```\n\nA few advantages of gRPC:\n\n1. It abstracts away the calls to a remote API\n2. Compatible with several popular languages\n3. It makes possible to work with native objects of your current programming language\n4. It generate the classes and object/messages for you from a `.proto` file\n\nFrom the dedicated file, it creates a gRPC server to receive requests from clients that themselves use a dynamic library generated via `protoc` and a dedicated plugin.\n\n![Architecture of gRPC](research/api/grpc-architecture.svg)\n\nThis diagram illustrate how different clients/servers written in different languages can work together with the gRPC server and _stubs_ (a client) created.\n\n## File upload\n\nAlthough a few users would recommend to use a [[research/api/rest|REST]] API to handle uploads, other says that it depends on the size of images and your app[^reddit_grpc_files].\n\nImplementing file uploading in gRPC seems to be done via `stream`s[^betterprogramming][^vinsguru], one of [its features](https://grpc.io/docs/what-is-grpc/core-concepts/#client-streaming-rpc). The core principle is to send files in small chunk (by default, gRPC limits incoming messages to¬†*4 MB* in case the developer hasn't thought about message size, but it can be increased[^sof_4mb]) Note that we send the metadata apart from the file, and it's not a standard so we have to define what's inside (path, name, extension/type...).\n\nImplementations seem to also use `oneof` keyword to avoid sending metadata each time we're sending a chunk of file.\n\n```protobuf\nmessage MetaData {\n\tstring filename = 1;\n\tstring extension = 2;\n}\n\nmessage FileUploadRequest {\n\toneof request {\n\t\tMetaData metadata = 1;\n\t\tbytes chunk = 2;\n\t}\n}\n```\n\n[^grpcio]: _Introduction to grpc_ (2022) _gRPC_. Available at: https://grpc.io/docs/what-is-grpc/introduction/ (Accessed: January 14, 2023).\n[^wikipedia]: _Remote procedure call_ (2023) _Wikipedia_. Wikimedia Foundation. Available at: https://en.wikipedia.org/wiki/Remote_procedure_call (Accessed: January 14, 2023).\n[^googlecloud]: Nally, M. (2020) _GRPC vs rest: Understanding grpc, openapi and rest and when to use them in API design | google cloud blog_, _Google_. Google. Available at: https://cloud.google.com/blog/products/api-management/understanding-grpc-openapi-and-rest-and-when-to-use-them (Accessed: January 14, 2023).\n[^reddit_grpc_files]: _r/grpc - grpc is suitable to handle file uploads?_ (no date) _reddit_. Available at: https://www.reddit.com/r/grpc/comments/oj2k9n/grpc_is_suitable_to_handle_file_uploads/ (Accessed: January 14, 2023).\n[^betterprogramming]: Foong, N.W. (2022) _GRPC file upload and download in Python_, _Medium_. Better Programming. Available at: https://betterprogramming.pub/grpc-file-upload-and-download-in-python-910cc645bcf0 (Accessed: January 14, 2023).\n[^vinsguru]: vIns (2022) _GRPC file upload with client streaming_, _Vinsguru_. Available at: https://www.vinsguru.com/grpc-file-upload-client-streaming/ (Accessed: January 14, 2023).\n[^sof_4mb]: Anderson, E. (2019) _Should I transmit large data sets via grpc without manual chunking?_, _Stack Overflow_. Available at: https://stackoverflow.com/a/58435745 (Accessed: January 14, 2023).\n","lastmodified":"2023-02-02T11:28:17.188598449Z","tags":null},"/research/api/json":{"title":"JSON","content":"\n\u003e [!quote] From the official website\n\u003e\n\u003e **JSON**¬†(JavaScript Object Notation) is a lightweight data-interchange format. It is easy for humans to read and write. It is easy for machines to parse and generate.\n\u003e\n\u003e \u003csmall\u003e_Introducing json_ (no date) _JSON_. Available at: https://www.json.org/json-en.html (Accessed: January 13, 2023).\u003c/small\u003e\n\nIt's a serialisation format that is human-friendly, meaning objects, arrays and values are represented in a string. Example:\n\n```json\n{\n  \"name\": \"Simon\",\n  \"surname\": \"Leonard\",\n  \"age\": 21,\n  \"hobbies\": [\"cooking\", \"reading\", \"drinking coffee\"],\n  \"enemies\": null\n}\n```\n\nHere is a speculative object that could represent me in JSON.\n\nThis time, let's say I have a array of users:\n\n```json\n{\n  \"users\": [\n    {\n      \"id\": \"12345\",\n      \"name\": \"Simon\",\n      \"surname\": \"Leonard\",\n      \"age\": 21,\n      \"hobbies\": [\"cooking\", \"reading\", \"drinking coffee\"],\n      \"allies\": [\"54321\"]\n    },\n    {\n      \"id\": \"54321\",\n      \"name\": \"Lucas\",\n      \"surname\": \"Thomas\",\n      \"age\": 22,\n      \"hobbies\": [],\n      \"allies\": [\"12345\"]\n    }\n  ]\n}\n```\n\nWe can see that JSON has at least one drawback: the document's structure and the data are mixed. You can see above that we repeat the keys `id`, `name`, `surname`... for multiple users.\n\n\u003e [!question] Is it possible to transfer a file over JSON?\n\u003e\n\u003e Although protocols like REST and gRPC are more suitable for the task (with multipart upload and stream respectively), one could upload a file by encoding it in base64. Note that it increase the data size by ~33%[^33-percent]\n\n[^33-percent]: T, D. and B, S. (2019) _Posting a file and associated data to a restful webservice preferably as JSON_, _Stack Overflow_. Available at: https://stackoverflow.com/a/4083908 (Accessed: January 5, 2023).\n","lastmodified":"2023-02-02T11:28:17.188598449Z","tags":null},"/research/api/protobuf":{"title":"Protocol Buffers","content":"\n[Protobuf or Protocol Buffers](https://developers.google.com/protocol-buffers) is a binary serialisation format that needs type definition beforehand. It's created by Google. This allows to omit structure from the data serialised, as client and server know what it is about.\n\n\u003e [!quote]\n\u003e\n\u003e Protocol buffers are a language-neutral, platform-neutral extensible mechanism for serializing structured data.\n\u003e \u003csmall\u003e_Protocol buffers | google developers_ (no date) _Google_. Google. Available at: https://developers.google.com/protocol-buffers (Accessed: January 13, 2023).\u003c/small\u003e\n\nTo demonstrate how it's working, I've recreated the same structure as in the [[research/api/json|JSON]] page.\n\nA _type_ in protobuf is called a `message`. Messages are defined in a `.proto` file. Let's create a list of people, and see how it's serialised compared to JSON.\n\n```protobuf\nsyntax = \"proto3\";\npackage file;\n\nmessage Person {\n    string id = 1;\n    string name = 2;\n    string surname = 3;\n    uint32 age = 4;\n    repeated string hobbies = 5;\n    repeated string allies = 6;\n}\n\nmessage PersonList {\n    repeated Person users = 1;\n}\n```\n\nBefore going further, each property has an identifier (the numbers). They are used in serialisation.\n\nI made a little experiment in JavaScript using [protobufjs](https://www.npmjs.com/package/protobufjs) to compare the length of messages in JSON (string) and Protobuf (binary):\n\n```js\nconst protobuf = require(\"protobufjs\")\n\nconst simon = {\n  id: \"12345\",\n  name: \"Simon\",\n  surname: \"Leonard\",\n  age: 21,\n  hobbies: [\"coding\", \"reading\", \"writing\"],\n  allies: [\"54321\"],\n}\n\nconst lucas = {\n  id: \"54321\",\n  name: \"Lucas\",\n  surname: \"Thomas\",\n  age: 22,\n  hobbies: [],\n  allies: [\"12345\"],\n}\n\nconst root = protobuf.loadSync(\"file.proto\")\n\nconst Person = root.lookupType(\"file.Person\")\n\nvar simonBuf = Person.create(simon)\nvar lucasBuf = Person.create(lucas)\n\nconst PersonList = root.lookupType(\"file.PersonList\")\nconst users = PersonList.create({ users: [simonBuf, lucasBuf] })\nconst dataUsers = PersonList.encode(users).finish()\n\nconsole.log(\"proto-serialized=\" + dataUsers.length)\nconsole.log(\"json-serialized=\" + JSON.stringify(users).length)\n```\n\nThe score for proto is 93 bytes, and 207 for JSON.\n\n\u003e [!info] Info\n\u003e\n\u003e When a protobufjs object like Person or Personlist gets serialised as JSON, like the last line in the script above, then it uses the JavaScript equivalent, so the result is not biased.\n\nWith a few more line, we can infer what the proto-serialised message look like:\n\n```js\nconsole.log(dataUsers) // \u003cBuffer 0a 3a 0a 05 31 32 33 34 35 12 05 53 69 6d 6f 6e 1a 07 4c 65 6f 6e 61 72 64 20 15 2a 06 63 6f 64 69 6e 67 2a 07 72 65 61 64 69 6e 67 2a 07 77 72 69 74 ... 43 more bytes\u003e\nconsole.log(dataUser.toString())\n//\n// :\n// 12345SimonLeonard *coding*reading*writing254321\n//\n// 54321LucasThomas 212345\n```\n","lastmodified":"2023-02-02T11:28:17.188598449Z","tags":null},"/research/api/rest":{"title":"REST","content":"\nREST (_Representational state transfer_) is a style of software architecture that takes advantage of HTTP(S):\n\n- The path represent a resource\n- A verb represent what kind of operation has to be done\n- Headers are used for various things, like authorisation token\n- The body for the actual data, when needed, nowadays mostly [[research/api/json]] for APIs\n- The return status tells quickly if everything happened as expected\n\nLet's say we have a database of recipes. We want to list them, add, modify and delete them. This can be done with a meaningful base path like `/recipes`. An API following REST principles would have those couples verbs/paths:\n\n- `GET /recipes` to have a list of them (complete or partial objects, maybe with pagination)\n- `POST /recipes` to add one\n- `PUT /recipes/:id` or `PATCH /recipes/:id` to modify a recipe fully or partially (where id is a unique identifier of the resource)\n- `DELETE /recipes/:id` to delete it\n\n## File upload\n\nFor uploading files, we have several options. One is to use base64 encoding and put the result in JSON, but it's not the best option for large files. Although we might never have big files (because we exchange coding files), it is something to consider for assets for example.\n\nAnother way of doing this through a `multipart/form-data` request[^multipart]. The principle is to first upload the files independently from their metadata or any data you could send. Either first upload the files, get IDs and link them to the metadata (server controls names/ids) or upload metadata first and then files (client controls names/ids).\n\n[^multipart]: libik and kirk (2020) _REST API - file (ie images) processing - best practices_, _Stack Overflow_. Available at: https://stackoverflow.com/questions/33279153/rest-api-file-ie-images-processing-best-practices (Accessed: January 13, 2023).\n","lastmodified":"2023-02-02T11:28:17.188598449Z","tags":null}}