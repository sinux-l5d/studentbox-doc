{"/":{"title":"üë®‚Äçüíª Studentbox documentation","content":"\n_Studentbox_ is a project that aims to make deployment easy for student üë®‚Äçüéì, and management of hosted projects simple for a teacher üë®‚Äçüè´.\n\n# üåç Context\n\nI've realised this project during my BSc (Hons)[^bsc] at [Dundalk Institute of Technology](https://www.dkit.ie/). The curriculum is about _Cloud Computing_, and so this project has to take advantage of different cloud aspects like including scaling, APIs[^api] and automation etc.\n\nSee the [[about-me|About me]] page this know more about the author.\n\n# ü•ú In a nutshell...\n\n_Studentbox_ wants to archive the following goals:\n\n- Host the students' projects in an isolated environment, without impacting other projects or host system\n- Provide a complete environment for the apps supported\n- Be able to deploy in a single command line...\n  - PHP app using MySQL\n  - Node.js app using MongoDB or MySQL\n- The _CLI_[^cli] client should...\n  - work on Linux, Mac and Windows\n  - be easy to setup\n  - be usable by both student and teacher\n- Make possible live-reloading while developing\n\nWhile having the following constraints:\n\n- Hostable on AWS\n- Self-hostable on an on-premise server\n\nYou can access the [[project/goals|goals]] page to know more about the project's goals and the [[project/road-map|road map]].\n\n[^bsc]:\n    **B**achelor of **Sc**ience (**Hon**our**s**) is the 4th year after secondary school (in Ireland).\n    In France, the equivalent year is the 1st year of Master's degree (the 4th year after _Lyc√©e_).\n\n[^api]: **A**pplication **P**rogramming **I**nterface in IT is an abstraction layer to interact with things we don't want to deal manually with. In this curriculum, we're talking about Web APIs (REST with JSON among others).\n[^cli]:\n    **C**ommand **L**ine **I**nterface, as the opposit of Graphical User Interface (GUI) is a text-based interface.\n    On Windows, it's in CMD/PowerShell. On Linux, it's in your favourite terminal \u0026 shell (bash, zsh...)\n","lastmodified":"2023-01-13T12:46:27.119834368Z","tags":null},"/about-me":{"title":"About me üôã‚Äç‚ôÇÔ∏è","content":"\nMy name is Simon LEONARD. This project has been produced during my 4th year after secondary school/_Lyc√©e_. \n\nWhy am I not writing BSc Hons? And why do I use the French word _Lyc√©e_?\n\nBecause I'm currently a French student, and I'm in a Erasmus+ exchange year in [Dundalk Institute of Technologies](https://www.dkit.ie/) at the time of writing.\\\nAt DkIT I'm following the course _Computing in Cloud Computing_, meanwhile at [Universit√© Savoie Mont-Blanc](https://univ-smb.fr/en) I'm enrolled in the [CMI programme](https://reseau-figure.fr/about-cmi/?lang=en) for IT, which is basically a bundle of BSc + BSc (hons) + MSc + additional courses on 5 years.\n\nSee my [Linkedin](https://linkedin.com/in/simon-l5d) and [Github](https://github.com/sinux-l5d).","lastmodified":"2023-01-13T12:46:27.119834368Z","tags":null},"/project/goals":{"title":"Goals üéØ","content":"\n# Back end\n\nThe back end should be either hosted on AWS or an on-premise server.\n\nAmazon's cloud would be useful if one needs to easily scale as more students use it.\nOn another hand, an on-premise server allow flexibility and complete control other data, privacy and hosting.\n\nThis means that I cannot use AWS's specific service, or at least not without increasing development cost.\n\nFinally, an easy/automated installation would save time.\n\n## Isolate process\n\nWe don't want that students' project impact other's by accident or on purpose.\n\nIf a web app crash, is heavily dealing with I/O, or is stuck in a infinite loop, it should impact as little as possible other projects.\n\n## Data exchange\n\nThe API should be bidirectional, for let's say uploading files and getting live logs of the back end.\n\n## Live reload\n\nLive reload is a convenient feature to allow to see changes as soon as a file is saved. In our case, that would mean upload the changed files and eventually restart the webapp.  \n\n## Users \u0026 permissions\n\nStudent and teachers are both users. Teachers can host his own project, for demonstration purpose let's say. He can invite students to register in his class, and manage the projects associated.\n\n## Git integration üí°\n\nUse Git as part of the API, as a backup/rollback system.\nEach project would have a repository.\n\n# CLI\n\nA CLI client for all users. A student should be able to deploy his project, retrieve logs (possibly in live), get link. A teacher has the same rights as student, plus managing resources, users, projects.\n\nBecause most users use Windows, the CLI needs to be cross platform.\n\n# Front end\n\nSimple webapp that allow the same thing as CLI, in a more graphical manner. No install, drag and drop zip/archive to deploy. \nNote for the ZIP: mind that code might be at root of the archive, not in a top-level directory.\n\nIt should present live logs, just like CLI.\n","lastmodified":"2023-01-13T12:46:27.119834368Z","tags":null},"/project/road-map":{"title":"Road map üó∫Ô∏è","content":"\n\n# Research üîé\n\nThis section treats about everything that needs to be researched before starting to code.\n\n## API \n\nCompare API types, knowing I want to transfer files, and need live-capabilities.\n\n### JSON\n\nSee [[research/api/json|JSON]]\n\n\u003c!-- ![JSON](research/api/json) --\u003e\n\n### REST \n\nSee [[research/api/rest|REST]].\n\n\n### GraphQL\n\nSee [[research/api/graphql|GraphQL]].\n\n### gRPC \u0026 Protobuf\n\nSee [[research/api/protobuf|Protobuf]].\n\n## Sand-boxing processes \n\nIt's important that each project is isolated from others and eventually from the host. I need a lightweight system that allow to easily add/remove new project, limiting disk/CPU/memory usage.\n\n### Container approach\n\n#### Docker\n\n#### Podman\n\n#### Kubernetes\n\nSee implementations and API\n\n### Virtual Machines approach\n\n#### Vagrant\n\n#### Self-managed\n\n#### AWS-managed\n\n## Programming language \n\n## Storage\n\nThe app will 2 different types of data: metadata (users, permissions) and the projects themselves (files).\nWhat type of database? Why?\n\n### Users, permissions, projects...\n\n### Projects\n\n## Logic\n\n### Defining permissions\n\n### Recipe for minimal deploy\n\nAll student in mind, write down the simplest way for a user to deploy his php/node.js app.\n\n# Choosing tech stack (by 16th of January)\n\nOnce research is done, make choices.\n\n# Realising","lastmodified":"2023-01-13T12:46:27.119834368Z","tags":null},"/research/api/graphql":{"title":"graphql","content":"\n\u003e [!quote] According to the official website\n\u003e\n\u003e GraphQL is a query language for APIs and a runtime for fulfilling those queries with your existing data. GraphQL provides a complete and understandable description of the data in your API, gives clients the power to ask for exactly what they need and nothing more, makes it easier to evolve APIs over time, and enables powerful developer¬†tools.\n\u003e\n\u003e \u003csmall\u003e_GraphQL | A query language for you API_ (no date) _GraphQL_. Available at: https://graphql.org/ (Accessed: January 13, 2023).\u003c/small\u003e\n\nFirst thing we notice is that GraphQL is not just a API specification but a full runtime[^aimuliple] unlike [[research/api/rest|REST]] which is just a specification.\n\nFor GraphQL, just as for [[research/api/grpc|gRPC]], we need to write specification of the objects we will transfer beforehand. In the GraphQL word, it's called *type definitions* and types contains *fields*.\n\n\u003e [!example] Example from the official website\n\u003e\n\u003e First describe the objects\n\u003e ```graphql\n\u003e type Project {\n\u003e   name: String\n\u003e   tagline: String\n\u003e   contributors: [User]\n\u003e }\n\u003e ```\n\u003e\n\u003e Then query whatever you want\n\u003e ```graphql\n\u003e {\n\u003e   project(name: \"GraphQL\") {\n\u003e     tagline\n\u003e   }\n\u003e }\n\u003e ```\n\u003e\n\u003e The result will be formatted just like the query\n\u003e ```graphql\n\u003e {\n\u003e   \"project\": {\n\u003e     \"tagline\": \"A query language for APIs\"\n\u003e   }\n\u003e }\n\u003e ```\n\nThose type definition being in separate files, it's easy to document the API automatically with tools like [GraphiQL](https://github.com/graphql/graphiql).\n\nOne of the advantages of this query approach is its precision, allowing to have all the data we need at once, without the need to fetch multiple times like it's the case for REST.\n\n## File upload\n\nJust like for REST, we could encode files in base64 to upload them. But that adds overhead for both server and client, increase the file size by ~33%[^wundergraph].\n\nJust like for REST, we could use a multipart request but:\n\n\u003e [!quote] Quote from Jens Neuse[^wundergraph]\n\u003e\n\u003e  Unfortunately, there's no standard to handle Multipart Requests with GraphQL.¬†This means, your solution will not be easily portable across different languages or implementations¬†and your client implementation depends on the exact implementation of the server.\n\nSo one of the other approach is to have another homemade API in REST that takes care of files only, or using AWS S3. The last option is not viable if we want to keep our system independent from cloud.\n\nThe article I relied on is made by Jens Neuse at [WunderGraph](https://wundergraph.com), described as \"The¬†simplicity of RPC withthe¬†power of GraphQL\" on there website. That could be a solution, but would lock us in a not-so-well-known solution, and we don't control the prices. If I where to use RPC, I would probably go with [[research/api/grpc|gRPC]] which is free, opensource and licensed Apache-2.0.\n\n[^aimuliple]: Ataman, A. (2023) _Graphql vs. rest in 2023: Top 4 advantages \u0026 disadvantages_, _AIMultiple_. Available at: https://research.aimultiple.com/graphql-vs-rest/ (Accessed: January 13, 2023). \n[^wundergraph]: Neuse, J. (2021) _GraphQL file uploads - evaluating the 5 most common approaches_, _WunderGraph_. Available at: https://wundergraph.com/blog/graphql_file_uploads_evaluating_the_5_most_common_approaches (Accessed: January 13, 2023).","lastmodified":"2023-01-13T12:46:27.119834368Z","tags":null},"/research/api/json":{"title":"json","content":"\n\u003e [!quote] From the official website\n\u003e\n\u003e **JSON**¬†(JavaScript Object Notation) is a lightweight data-interchange format. It is easy for humans to read and write. It is easy for machines to parse and generate.\n\u003e \n\u003e \u003csmall\u003e_Introducing json_ (no date) _JSON_. Available at: https://www.json.org/json-en.html (Accessed: January 13, 2023).\u003c/small\u003e\n\nIt's a serialisation format that is human-friendly, meaning object, arrays and values are represented in a string. Example:\n\n```json\n{\n\t\"name\": \"Simon\",\n\t\"surname\": \"Leonard\",\n\t\"age\": 21,\n\t\"hobbies\": [\n\t\t\"cooking\",\n\t\t\"reading\",\n\t\t\"drinking coffee\"\n\t],\n\t\"enemies\": null\n}\n```\n\nHere is a speculative object that could represent me in JSON.\n\nThis time, let's say I have a array of users:\n\n```json\n{\n\t\"users\": [\n\t\t{\n\t\t\t\"id\": \"12345\",\n\t\t\t\"name\": \"Simon\",\n\t\t\t\"surname\": \"Leonard\",\n\t\t\t\"age\": 21,\n\t\t\t\"hobbies\": [\n\t\t\t\t\"cooking\",\n\t\t\t\t\"reading\",\n\t\t\t\t\"drinking coffee\"\n\t\t\t],\n\t\t\t\"allies\": [\n\t\t\t\t\"54321\"\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"id\": \"54321\",\n\t\t\t\"name\": \"Lucas\",\n\t\t\t\"surname\": \"Thomas\",\n\t\t\t\"age\": 22,\n\t\t\t\"hobbies\": [],\n\t\t\t\"allies\": [\n\t\t\t\t\"12345\"\n\t\t\t]\n\t\t}\n\t]\n}\n```\n\nWe can see that JSON as at least one drawback: the document's structure and the data are mixed. You can see above that we repeat the keys `id`, `name`, `surname`... for multiple users.\n\n\u003e [!question] Is it possible to transfer a file over JSON?\n\u003e\n\u003e Although protocols like REST and gRPC are more suitable for the task (with multipart upload and stream respectively), one could upload a file by encoding it in base64. Note that it increase the data size by ~33%[^33-percent]\n\n[^33-percent]: https://stackoverflow.com/questions/4083702/posting-a-file-and-associated-data-to-a-restful-webservice-preferably-as-json","lastmodified":"2023-01-13T12:46:27.119834368Z","tags":null},"/research/api/protobuf":{"title":"Protobuf","content":"\n[Protobuf](https://developers.google.com/protocol-buffers) is a serialisation format that needs type definition beforehand. It's created by Google. This allow to omit structure from the data serialised, as client and server know what it is about.\n\n\u003e [!quote]\n\u003e\n\u003e Protocol buffers are a language-neutral, platform-neutral extensible mechanism for serializing structured data.\n\u003e \u003csmall\u003e*Protocol Buffers. (n.d.). Google. Retrieved January 5th, 2023, from https://developers.google.com/protocol-buffers*\u003c/small\u003e\n\nTo demonstrate how it's working, I've recreated the same structure as in the [[research/api/json|Json]] page.\n\nA *type* in protobuf is called a `message`. Messages are defined in a `.proto` file. Let's create a list of people, and see how it's serialised compared to Json.\n\n```protobuf\nsyntax = \"proto3\";\npackage file;\n\nmessage Person {\n    string id = 1;\n    string name = 2;\n    string surname = 3;\n    uint32 age = 4;\n    repeated string hobbies = 5;\n    repeated string allies = 6;\n}\n\nmessage PersonList {\n    repeated Person users = 1;\n}\n```\n\nBefore going further, each property has a identifier (the numbers). They are used in serialisation.\n\nI made a little experiment in JavaScript using [protobufjs](https://www.npmjs.com/package/protobufjs) to compare the length of messages in Json and Protobuf:\n\n```js\nconst protobuf = require(\"protobufjs\");\n\nconst simon = {\n  id: \"12345\",\n  name: \"Simon\",\n  surname: \"Leonard\",\n  age: 21,\n  hobbies: [\"coding\", \"reading\", \"writing\"],\n  allies: [\n    \"54321\",\n  ],\n};\n\nconst lucas = {\n  id: \"54321\",\n  name: \"Lucas\",\n  surname: \"Thomas\",\n  age: 22,\n  hobbies: [],\n  allies: [\n    \"12345\",\n  ],\n};\n\nconst root = protobuf.loadSync(\"file.proto\");\n\nconst Person = root.lookupType(\"file.Person\");\n\nvar simonBuf = Person.create(simon);\nvar lucasBuf = Person.create(lucas);\n\nconst PersonList = root.lookupType(\"file.PersonList\");\nconst users = PersonList.create({ users: [simonBuf, lucasBuf] });\nconst dataUsers = PersonList.encode(users).finish();\n\nconsole.log(\"proto-serialized=\" + dataUsers.length);\nconsole.log(\"json-serialized=\" + JSON.stringify(users).length)\n```\n\nThe score for proto is 93 bytes, and 207 for JSON.\n\nWith a few more line, we can infer what the proto-serialised message look like:\n```js\nconsole.log(dataUsers) // \u003cBuffer 0a 3a 0a 05 31 32 33 34 35 12 05 53 69 6d 6f 6e 1a 07 4c 65 6f 6e 61 72 64 20 15 2a 06 63 6f 64 69 6e 67 2a 07 72 65 61 64 69 6e 67 2a 07 77 72 69 74 ... 43 more bytes\u003e\nconsole.log(dataUser.toString())\n//\n// :\n// 12345SimonLeonard *coding*reading*writing254321\n//\n// 54321LucasThomas 212345\n```","lastmodified":"2023-01-13T12:46:27.119834368Z","tags":null},"/research/api/rest":{"title":"REST","content":"\nREST (*Representational state transfer*) is a style of software architecture that takes advantage of HTTP(S):\n- The path represent a resource\n- A verb represent what kind of operation has to be done\n- Headers are used for various things, like authorisation token\n- The body for the actual data, when needed, nowadays mostly [[research/api/json]] for APIs\n- The return status tells quickly if everything happened as expected\n\nLet's say we have a database of recipe. We want to list them, add, modify and delete them. This can be done with a meaningful base path like `/recipes`. An API following REST principles would have those couples verbs/paths:\n- `GET /recipes` to have a list of them (complete or partial objects, maybe with pagination) \n- `POST /recipes` to add one\n- `PUT /recipes/:id` or `PATCH /recipes/:id` to modify a recipe fully or partially (where id is a unique identifier of the resource)\n- `DELETE /recipes/:id` to delete it\n\n## File upload\n\nFor uploading file, we have several options. One is to use base64 encoding and put the result in JSON, but it's not the best option for large file. Although we might never have big files (because we exchange coding files), it is something to consider for assets for example.\n\nAnother way of doing is through a `multipart/form-data` request[^multipart]. The principle is to first upload the files independently from there metadata or any data you could send. Either first upload the files, get IDs and link them to the metadata (server controls names/ids) or upload metadata first and then files (client controls names/ids).\n\n[^multipart]: libik and kirk (2020) _REST API - file (ie images) processing - best practices_, _Stack Overflow_. Available at: https://stackoverflow.com/questions/33279153/rest-api-file-ie-images-processing-best-practices (Accessed: January 13, 2023).","lastmodified":"2023-01-13T12:46:27.119834368Z","tags":null}}